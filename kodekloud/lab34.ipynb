{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30607550",
   "metadata": {},
   "source": [
    "# Lab 34: LangChain Agents with Tool Calling\n",
    "\n",
    "## Overview\n",
    "This lab introduces **LangChain Agents** - intelligent systems that can reason about which tools to use and how to use them to accomplish tasks. Unlike simple chains that follow predefined paths, agents can make decisions dynamically based on the input and available tools.\n",
    "\n",
    "## Key Concepts\n",
    "- **Tool Calling Agents**: Agents that can invoke external tools and APIs\n",
    "- **Agent Executor**: The runtime environment that manages agent execution\n",
    "- **Agent Memory**: Maintaining conversation history across interactions\n",
    "- **Dynamic Tool Selection**: How agents choose which tools to use for specific tasks\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the difference between chains and agents\n",
    "- Create tool-calling agents with external search capabilities\n",
    "- Implement agent memory for contextual conversations\n",
    "- Configure agent execution with proper error handling\n",
    "- Learn agent reasoning patterns and decision-making processes\n",
    "\n",
    "## What You'll Build\n",
    "A conversational agent that can:\n",
    "1. Search the web for current information using Tavily\n",
    "2. Maintain conversation context across multiple interactions\n",
    "3. Reason about when and how to use tools\n",
    "4. Provide informed responses based on retrieved information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b386c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries for Agent Creation\n",
    "\n",
    "# Core LangChain components for building conversational agents\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# OpenAI integration for language model capabilities\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Tavily search tool for real-time web search capabilities\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Agent creation and execution components\n",
    "from langchain.agents import create_tool_calling_agent, tool\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "# Environment variable management\n",
    "import os\n",
    "\n",
    "# Agent Architecture Overview:\n",
    "# 1. ChatPromptTemplate: Structures the conversation format for the agent\n",
    "# 2. MessagesPlaceholder: Handles dynamic insertion of chat history\n",
    "# 3. ChatMessageHistory: Stores conversation context across interactions\n",
    "# 4. RunnableWithMessageHistory: Adds memory capabilities to agents\n",
    "# 5. create_tool_calling_agent: Creates agents that can invoke external tools\n",
    "# 6. AgentExecutor: Manages the execution loop and tool calling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b76c1f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Configure Tavily Search Tool\n",
    "\n",
    "# Set up Tavily API credentials for web search functionality\n",
    "# Tavily provides AI-optimized search results specifically designed for LLM applications\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"API_KEY\"  # Replace with your actual API key\n",
    "\n",
    "# Initialize the Tavily search tool\n",
    "# TavilySearchResults returns structured search results with:\n",
    "# - Relevant web content summaries\n",
    "# - Source URLs for verification\n",
    "# - Metadata about search quality and relevance\n",
    "search = TavilySearchResults()\n",
    "\n",
    "# Why Tavily for Agents?\n",
    "# - Optimized for AI applications with clean, structured output\n",
    "# - Reduces hallucination by providing current, factual information\n",
    "# - Includes source attribution for transparency and verification\n",
    "# - Designed to work seamlessly with LangChain agent workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf725d9f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create Agent Prompt Template\n",
    "\n",
    "# Design a conversation structure that enables proper agent reasoning\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # System message: Sets the agent's behavior and reasoning approach\n",
    "        (\"system\", \"You are a helpful assistant. Think step by step before responding.\"),\n",
    "        \n",
    "        # Chat history placeholder: Injects previous conversation context\n",
    "        # This enables the agent to maintain continuity across interactions\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        \n",
    "        # Human input: The current user query or request\n",
    "        (\"human\", \"{input}\"),\n",
    "        \n",
    "        # Agent scratchpad: Space for the agent's reasoning and tool calling process\n",
    "        # This is where the agent records its thoughts and tool execution results\n",
    "        (\"placeholder\", \"{agent_scratchpad}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Prompt Template Structure Explanation:\n",
    "# 1. System Message: Establishes agent personality and reasoning approach\n",
    "# 2. Chat History: Provides context from previous conversation turns\n",
    "# 3. Human Input: Contains the current user query requiring response\n",
    "# 4. Agent Scratchpad: Working space for agent reasoning and tool results\n",
    "\n",
    "# The \"step by step\" instruction encourages the agent to:\n",
    "# - Analyze the query carefully\n",
    "# - Determine if tools are needed\n",
    "# - Plan the sequence of actions\n",
    "# - Execute tools systematically\n",
    "# - Synthesize results into a coherent response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a40055a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Language Model for Agent\n",
    "\n",
    "# Configure OpenAI API credentials\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"api_key\"  # Replace with your actual API key\n",
    "\n",
    "# Initialize ChatOpenAI model for agent reasoning\n",
    "# The LLM serves as the \"brain\" of the agent, responsible for:\n",
    "# - Understanding user queries\n",
    "# - Deciding which tools to use\n",
    "# - Reasoning about tool outputs\n",
    "# - Generating final responses\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Why ChatOpenAI for Agents?\n",
    "# - Strong reasoning capabilities for tool selection\n",
    "# - Excellent at following complex prompt instructions\n",
    "# - Reliable function calling support for tool integration\n",
    "# - Good balance of speed and intelligence for agent workflows\n",
    "\n",
    "# Agent LLM Requirements:\n",
    "# - Function calling support (for tool invocation)\n",
    "# - Strong reasoning capabilities (for decision making)\n",
    "# - Instruction following (for prompt adherence)\n",
    "# - Context management (for conversation continuity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551675a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define Agent Tools\n",
    "\n",
    "# Create the tools list that the agent can access and use\n",
    "# Each tool in this list becomes available for the agent to invoke\n",
    "tools = [search]\n",
    "\n",
    "# Tool Selection Process:\n",
    "# 1. Agent analyzes the user query\n",
    "# 2. Determines if external information is needed\n",
    "# 3. Selects appropriate tool(s) from available options\n",
    "# 4. Executes tool with relevant parameters\n",
    "# 5. Processes tool output for response generation\n",
    "\n",
    "# Available Tools in This Agent:\n",
    "# - TavilySearchResults: Web search for current information\n",
    "#   - Use case: Questions requiring recent data or facts\n",
    "#   - Input: Search query string\n",
    "#   - Output: Structured search results with sources\n",
    "\n",
    "# Tool Architecture Benefits:\n",
    "# - Modular design: Easy to add/remove tools\n",
    "# - Automatic integration: Tools work seamlessly with agent logic\n",
    "# - Standardized interface: All tools follow same calling pattern\n",
    "# - Error handling: Built-in error management for tool failures\n",
    "\n",
    "# Expanding Tool Capabilities:\n",
    "# You can extend this agent by adding more tools:\n",
    "# - Calculator tools for mathematical operations\n",
    "# - Database tools for structured data queries\n",
    "# - API tools for specific service integrations\n",
    "# - Custom tools for business-specific operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f61d5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create Message History for Agent Memory\n",
    "\n",
    "# Initialize a message history object to store conversation context\n",
    "# This enables the agent to remember previous interactions\n",
    "message_history = ChatMessageHistory()\n",
    "\n",
    "# Memory Architecture:\n",
    "# - Stores both user messages and agent responses\n",
    "# - Maintains conversation context across multiple turns\n",
    "# - Enables reference to previous topics and information\n",
    "# - Supports follow-up questions and context-dependent queries\n",
    "\n",
    "# Memory Benefits for Agents:\n",
    "# 1. Contextual Understanding: Agent can reference previous conversation\n",
    "# 2. Follow-up Support: Users can ask \"tell me more\" or \"what about X?\"\n",
    "# 3. Efficiency: Avoids re-searching for previously retrieved information\n",
    "# 4. Natural Conversation: Creates more human-like interaction patterns\n",
    "\n",
    "# Memory Considerations:\n",
    "# - Token limits: Long conversations may exceed model context windows\n",
    "# - Privacy: Sensitive information persists in memory\n",
    "# - Performance: Large histories may slow down processing\n",
    "# - Cleanup: Consider clearing history for new conversation topics\n",
    "\n",
    "# Alternative Memory Options:\n",
    "# - RedisChatMessageHistory: Persistent storage across sessions\n",
    "# - FileChatMessageHistory: File-based storage for local persistence\n",
    "# - Custom memory: Application-specific memory implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788ac01",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create Tool-Calling Agent\n",
    "\n",
    "# Combine LLM, tools, and prompt into a cohesive agent\n",
    "# This creates the core agent that can reason and use tools\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Agent Creation Process:\n",
    "# 1. LLM provides reasoning and decision-making capabilities\n",
    "# 2. Tools define available external actions and data sources\n",
    "# 3. Prompt structures the conversation and reasoning format\n",
    "# 4. Agent combines these components into intelligent workflow\n",
    "\n",
    "# Tool-Calling Agent Features:\n",
    "# - Automatic tool selection based on query analysis\n",
    "# - Structured reasoning process with scratchpad tracking\n",
    "# - Integration of tool outputs into natural language responses\n",
    "# - Error handling for tool failures and invalid parameters\n",
    "\n",
    "# Agent Decision Making:\n",
    "# The agent follows this reasoning pattern:\n",
    "# 1. Analyze user input for intent and requirements\n",
    "# 2. Determine if external tools are needed\n",
    "# 3. Select appropriate tool(s) and parameters\n",
    "# 4. Execute tool calls and process results\n",
    "# 5. Synthesize information into coherent response\n",
    "# 6. Update conversation memory with interaction\n",
    "\n",
    "# Agent vs Chain Comparison:\n",
    "# - Chains: Predetermined sequence of operations\n",
    "# - Agents: Dynamic decision-making about tool usage\n",
    "# - Chains: Faster, more predictable execution\n",
    "# - Agents: More flexible, handles complex multi-step tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80bca2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Agent Executor\n",
    "\n",
    "# Create the execution environment that manages agent operations\n",
    "# AgentExecutor handles the complete agent lifecycle and tool orchestration\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,           # The reasoning agent created above\n",
    "    tools=tools,          # Available tools for the agent to use\n",
    "    verbose=False         # Set to True to see detailed execution logs\n",
    ")\n",
    "\n",
    "# Agent Executor Responsibilities:\n",
    "# 1. Input Processing: Parse and validate user queries\n",
    "# 2. Agent Invocation: Call the agent with structured input\n",
    "# 3. Tool Orchestration: Manage tool calls and error handling\n",
    "# 4. Output Management: Format and return agent responses\n",
    "# 5. Safety Controls: Implement guardrails and limits\n",
    "\n",
    "# Execution Flow:\n",
    "# User Input → Agent Executor → Agent Reasoning → Tool Calls → Response\n",
    "\n",
    "# Verbose Mode Benefits (set verbose=True to enable):\n",
    "# - See agent's step-by-step reasoning process\n",
    "# - Monitor tool selection and execution\n",
    "# - Debug issues with tool calls or responses\n",
    "# - Understand agent decision-making patterns\n",
    "\n",
    "# Agent Executor Configuration Options:\n",
    "# - max_iterations: Limit agent reasoning steps\n",
    "# - max_execution_time: Set timeout for agent operations\n",
    "# - early_stopping_method: Control when agent stops reasoning\n",
    "# - return_intermediate_steps: Include reasoning steps in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a519df8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create Agent with Memory Integration\n",
    "\n",
    "# Wrap the agent executor with memory capabilities for persistent conversations\n",
    "agent1 = RunnableWithMessageHistory(\n",
    "    agent_executor,                    # The core agent executor\n",
    "    lambda session_id: message_history, # Function returning message history\n",
    "    input_messages_key=\"input\",        # Key for user input in the message structure\n",
    "    history_messages_key=\"chat_history\", # Key for conversation history in prompts\n",
    ")\n",
    "\n",
    "# Memory Integration Architecture:\n",
    "# 1. User provides input with session configuration\n",
    "# 2. System retrieves conversation history for the session\n",
    "# 3. History gets injected into the prompt template\n",
    "# 4. Agent processes query with full conversation context\n",
    "# 5. Response and query are saved to message history\n",
    "\n",
    "# Session Management:\n",
    "# - session_id: Unique identifier for conversation threads\n",
    "# - Multiple sessions: Support parallel conversations\n",
    "# - Session isolation: Each conversation maintains separate context\n",
    "# - Session persistence: Conversations survive application restarts\n",
    "\n",
    "# Message Flow with Memory:\n",
    "# Input → History Retrieval → Context Injection → Agent Processing → Response + Save\n",
    "\n",
    "# Memory Configuration Parameters:\n",
    "# - input_messages_key: Where to find user input in invoke() call\n",
    "# - history_messages_key: Where to inject history in prompt template\n",
    "# - output_messages_key: Where to find agent response for storage\n",
    "\n",
    "# Benefits of Memory-Enabled Agents:\n",
    "# - Contextual responses that reference previous conversation\n",
    "# - Support for follow-up questions and clarifications\n",
    "# - Natural conversation flow with topic continuity\n",
    "# - Ability to build on previous search results and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebeeba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Execute Agent with Real-World Query\n",
    "\n",
    "# Invoke the agent with a current events query that requires web search\n",
    "# This demonstrates the agent's ability to retrieve and process real-time information\n",
    "response = agent1.invoke(\n",
    "    {\"input\": \"When is the ICC Men's T20 2024 World Cup scheduled?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session1\"}}\n",
    ")\n",
    "\n",
    "# Display the agent's response\n",
    "print(\"Agent Response:\")\n",
    "print(response['output'])\n",
    "\n",
    "# Agent Execution Process for This Query:\n",
    "# 1. Query Analysis: Agent identifies need for current sports information\n",
    "# 2. Tool Selection: Determines Tavily search is appropriate\n",
    "# 3. Search Execution: Performs web search for T20 World Cup 2024 schedule\n",
    "# 4. Result Processing: Extracts relevant dates and information\n",
    "# 5. Response Generation: Synthesizes findings into natural language answer\n",
    "\n",
    "# Why This Query Tests Agent Capabilities:\n",
    "# - Requires current information not in training data\n",
    "# - Tests tool selection logic (search vs other options)\n",
    "# - Demonstrates information extraction from search results\n",
    "# - Shows natural language synthesis of retrieved data\n",
    "\n",
    "# Session Configuration:\n",
    "# - session_id \"session1\": Creates persistent conversation thread\n",
    "# - Configurable settings: Allows runtime parameter modification\n",
    "# - Memory activation: Enables context preservation for follow-ups\n",
    "\n",
    "# Expected Agent Behavior:\n",
    "# 1. Recognizes query requires current sports schedule information\n",
    "# 2. Selects Tavily search tool automatically\n",
    "# 3. Executes search with relevant keywords\n",
    "# 4. Processes search results to find schedule details\n",
    "# 5. Formats response with dates, venues, and relevant details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee09f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Agent Memory with Follow-up Query\n",
    "\n",
    "# Ask a follow-up question that relies on context from the previous interaction\n",
    "# This tests the agent's ability to maintain conversation continuity\n",
    "followup_response = agent1.invoke(\n",
    "    {\"input\": \"Which teams are participating in that tournament?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session1\"}}\n",
    ")\n",
    "\n",
    "print(\"\\nFollow-up Response:\")\n",
    "print(followup_response['output'])\n",
    "\n",
    "# Memory Demonstration:\n",
    "# - \"that tournament\" refers to the T20 World Cup from previous query\n",
    "# - Agent maintains context without re-asking for clarification\n",
    "# - May reuse information from previous search or perform new search\n",
    "# - Shows natural conversation flow with contextual understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb6510",
   "metadata": {},
   "source": [
    "## Agent Behavior Analysis\n",
    "\n",
    "### Key Agent Capabilities Demonstrated\n",
    "1. **Autonomous Tool Selection**: Agent automatically chooses appropriate tools based on query analysis\n",
    "2. **Dynamic Reasoning**: Makes decisions about when and how to use external information\n",
    "3. **Context Preservation**: Maintains conversation history for natural follow-up interactions\n",
    "4. **Information Synthesis**: Combines tool outputs with reasoning to generate coherent responses\n",
    "5. **Error Resilience**: Handles tool failures and provides meaningful responses\n",
    "\n",
    "### Agent vs Traditional Chains\n",
    "| Feature | Traditional Chains | LangChain Agents |\n",
    "|---------|-------------------|------------------|\n",
    "| Execution Path | Predetermined sequence | Dynamic decision-making |\n",
    "| Tool Usage | Fixed tool calls | Intelligent tool selection |\n",
    "| Flexibility | Limited to designed flow | Adapts to query requirements |\n",
    "| Complexity | Simple, predictable | Advanced reasoning capabilities |\n",
    "| Use Cases | Known workflows | Open-ended problem solving |\n",
    "\n",
    "### Agent Decision-Making Process\n",
    "1. **Query Understanding**: Parse user input for intent and requirements\n",
    "2. **Context Analysis**: Consider conversation history and previous interactions\n",
    "3. **Tool Assessment**: Evaluate available tools for query relevance\n",
    "4. **Execution Planning**: Determine sequence of tool calls and reasoning steps\n",
    "5. **Result Integration**: Combine tool outputs with reasoning for final response\n",
    "\n",
    "## Key Takeaways and Production Considerations\n",
    "\n",
    "### Agent Architecture Benefits\n",
    "- **Flexibility**: Handle diverse queries without pre-programming specific flows\n",
    "- **Extensibility**: Easy to add new tools and capabilities\n",
    "- **Intelligence**: Reason about complex multi-step problems\n",
    "- **Context Awareness**: Maintain conversation state and user preferences\n",
    "- **Scalability**: Support multiple concurrent conversations with session management\n",
    "\n",
    "### Production Deployment Considerations\n",
    "- **Performance**: Agents may be slower than chains due to reasoning overhead\n",
    "- **Cost**: Multiple LLM calls for reasoning and tool selection increase costs\n",
    "- **Reliability**: More complex execution paths can introduce failure points\n",
    "- **Monitoring**: Need comprehensive logging for agent decision tracking\n",
    "- **Safety**: Implement guardrails for tool usage and response generation\n",
    "\n",
    "### Advanced Agent Patterns\n",
    "- **Multi-Agent Systems**: Multiple specialized agents working together\n",
    "- **Tool Composition**: Combining multiple tools for complex workflows\n",
    "- **Custom Tools**: Building domain-specific tools for business applications\n",
    "- **Agent Supervision**: Human-in-the-loop patterns for critical decisions\n",
    "- **Memory Management**: Sophisticated context and long-term memory systems\n",
    "\n",
    "### Real-World Applications\n",
    "- **Customer Support**: Intelligent help desk agents with access to knowledge bases\n",
    "- **Research Assistants**: Academic and business research with web access\n",
    "- **Data Analysis**: Agents that can query databases and generate insights\n",
    "- **Content Creation**: Writing assistants with fact-checking capabilities\n",
    "- **Process Automation**: Intelligent workflow orchestration with decision-making"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
