{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d99401b7",
   "metadata": {},
   "source": [
    "# Lab 11: Basic LangChain Chain with Schema Inspection\n",
    "\n",
    "This lab demonstrates the fundamentals of creating a LangChain chain using the pipe operator and introduces schema inspection capabilities. You'll learn:\n",
    "- How to build a basic chain with prompt → model → output parser\n",
    "- Understanding input and output schemas\n",
    "- Inspecting chain structure and data flow\n",
    "- Working with modern LangChain expression language (LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f2a73-9c84-4d3f-ae08-cc018f5e84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core LangChain components for building a basic chain\n",
    "# - ChatOpenAI: OpenAI's chat model interface\n",
    "# - ChatPromptTemplate: Template for structuring prompts\n",
    "# - StrOutputParser: Parser to convert model output to string\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3628e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API key - replace with your actual API key\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186324f-0fdd-41eb-940a-089833bce6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat prompt template with a placeholder for the question\n",
    "# The template defines the assistant's role and includes a variable {question}\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are a helpful assistant. \n",
    "    Answer the following question: {question}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1526589-d290-4848-89d1-298fd88e8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChatOpenAI model with default settings (GPT-3.5-turbo)\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0996e47d-0c7e-483f-bd6d-ea55bf34a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string output parser to convert the model's response to plain text\n",
    "# This parser extracts the content from the model's message format\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361ff9d-9a3d-46db-9945-060a3b7a82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain using the pipe operator (|) - LangChain Expression Language (LCEL)\n",
    "# Data flows: prompt → llm → output_parser\n",
    "# This creates a runnable sequence that can be invoked with input data\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ed2a1-48b7-46b0-a1b5-b7669592e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the chain with a specific question\n",
    "# The question value will replace {question} in the prompt template\n",
    "chain.invoke({\"question\":\"Tell me about The Godfather movie\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958017c9-5e12-4721-9f1c-a8b83eaf215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the chain's input schema - shows what data structure the chain expects\n",
    "# This helps understand the required input format and validation rules\n",
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66bd43-8042-44d8-9b8a-28e91b41003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the chain's output schema - shows what data structure the chain produces\n",
    "# This helps understand the format of the response data\n",
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4886e4a-b5fe-493b-9044-6b35434fd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the LLM's output schema specifically\n",
    "# This shows the raw format of the language model's response before parsing\n",
    "llm.output_schema.schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
