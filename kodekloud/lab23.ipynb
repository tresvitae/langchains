{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a3cdd0d",
   "metadata": {},
   "source": [
    "# Lab 23: Advanced PDF Processing with Text Splitting\n",
    "\n",
    "This lab demonstrates advanced PDF document processing by combining document loading with intelligent text splitting for RAG applications. You'll learn:\n",
    "- How to load PDF documents and split them into optimized chunks\n",
    "- Using `RecursiveCharacterTextSplitter` for intelligent text segmentation\n",
    "- Understanding chunk size and overlap parameters for better retrieval\n",
    "- Preparing documents for vector databases and similarity search\n",
    "- Building effective knowledge bases with properly chunked content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af44e79-f4fd-454e-b8c5-2b0d368be36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyPDFLoader for advanced PDF document processing and chunking\n",
    "# This lab extends basic PDF loading with intelligent text splitting capabilities\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58004d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API key for potential downstream RAG applications\n",
    "# While not directly used in document processing, this enables LLM integration\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7cc872-b9b8-4ecf-b161-d6aceac0c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyPDFLoader with the handbook PDF file path\n",
    "# This prepares the document for loading and subsequent text splitting\n",
    "loader = PyPDFLoader(\"data/handbook.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d4d3f5-aa26-4627-8692-e927f4f9c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF and split into individual pages as Document objects\n",
    "# Each page becomes a separate document with metadata (page number, source file)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266f709-4b13-462e-b7a8-37ed56259b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the structure of all loaded pages\n",
    "# Shows Document objects with page_content and metadata for each page\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e656e7-9c88-46d6-8168-1652409a7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total number of pages extracted from the PDF\n",
    "# This helps understand document size before text splitting\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cabc05-a15b-431e-9de7-1abc3b2771b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display content of the first page (index 0)\n",
    "# This shows the raw text content before intelligent chunking\n",
    "pages[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e4e38-0072-47c0-a3a9-1a7a9cf6c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RecursiveCharacterTextSplitter for intelligent text chunking\n",
    "# This splitter respects document structure and creates optimized chunks for RAG\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c998990-d469-46fc-bdec-94f0438b39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure RecursiveCharacterTextSplitter with optimal parameters\n",
    "# chunk_size=200: Maximum characters per chunk (balance between context and granularity)\n",
    "# chunk_overlap=50: Overlap between chunks to preserve context across boundaries\n",
    "# This configuration ensures good retrieval performance for RAG applications\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c095d05-4f6a-4af4-813f-d559f28f8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply intelligent text splitting to all pages\n",
    "# Converts large page content into smaller, semantically meaningful chunks\n",
    "# Each chunk maintains metadata from original pages plus new chunk information\n",
    "chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac762239-75e4-48a1-bad0-5299b006537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results of text splitting\n",
    "# Display all chunks, total count, and examine a specific chunk (index 2)\n",
    "# This shows how pages were split into smaller, manageable pieces for RAG\n",
    "chunks\n",
    "len(chunks)\n",
    "chunks[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
