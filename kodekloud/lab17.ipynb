{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96110b9",
   "metadata": {},
   "source": [
    "# Lab 17: Short-Term Memory with MessagesPlaceholder\n",
    "\n",
    "This lab demonstrates how to implement short-term memory in LangChain conversations using MessagesPlaceholder. You'll learn:\n",
    "- How to inject conversation history into prompts\n",
    "- Using `MessagesPlaceholder` for dynamic message insertion\n",
    "- Maintaining context across multiple interactions\n",
    "- Building conversational AI systems with memory capabilities\n",
    "- Managing conversation flow and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d48ac8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Short-Term Memory Implementation with LangChain\n",
    "# Import necessary components for conversation memory functionality\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# Configure OpenAI API key for language model access\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "# Initialize ChatOpenAI model for conversational interactions\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# Create a chat prompt template with memory capabilities\n",
    "# MessagesPlaceholder allows dynamic injection of conversation history\n",
    "# The \"history\" variable_name will be used to pass previous messages\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're an assistant who's good at {ability}. Respond in 20 words or fewer\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),  # Dynamic history injection point\n",
    "        (\"human\", \"{input}\"),  # Current user input\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the base conversational chain\n",
    "base_chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17da1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define conversation history as a list of message tuples\n",
    "# Each tuple contains (role, content) where role is \"human\" or \"ai\"\n",
    "# This represents the previous exchange about right-angled triangles\n",
    "history = [\n",
    "    (\"human\", \"What's a right-angled triangle?\"),\n",
    "    (\"ai\", \"A right-angled triangle has one angle of 90 degrees, with the other two angles summing to 90 degrees.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a64743",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Invoke chain WITHOUT conversation history\n",
    "# This call lacks context - the model won't know what \"other types\" refers to\n",
    "# The response will be generic since no history is provided\n",
    "base_chain.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"What are the other types?\"}, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dcc268",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Invoke chain WITH conversation history included\n",
    "# Now the model has context from previous conversation about triangles\n",
    "# The \"history\" parameter injects previous messages into MessagesPlaceholder\n",
    "# The model can now understand that \"other types\" refers to other types of triangles\n",
    "base_chain.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"What are the other types?\", \"history\": history}, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
