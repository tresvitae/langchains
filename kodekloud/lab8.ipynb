{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff347f38",
   "metadata": {},
   "source": [
    "# Lab 8: LangChain Debugging with Global Debug\n",
    "\n",
    "This lab demonstrates how to use LangChain's global debugging feature to trace chain execution. You'll learn how to:\n",
    "- Enable global debugging with `set_debug(True)`\n",
    "- Observe detailed execution flow and timing\n",
    "- Use the modern pipe operator (`|`) syntax for chain composition\n",
    "- Debug complex chain interactions step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a237a-a117-43b7-a1e2-e7802a12ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for LangChain debugging demonstration\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API key - replace with your actual API key\n",
    "# This is required for the ChatOpenAI model to function\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_API_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccffd05a-01ce-4825-a9ab-10d22c3f6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable global debugging for LangChain\n",
    "# This will print detailed information about chain execution including:\n",
    "# - Input/output at each step\n",
    "# - Timing information\n",
    "# - Internal chain operations\n",
    "from langchain.globals import set_debug\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3622df-50b5-435b-a070-3e47d381f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat prompt template with system and human messages\n",
    "# The template uses variables {subject} and {concept} for dynamic content\n",
    "prompt=ChatPromptTemplate.from_messages([(\"system\",\"You are a {subject} teacher\"),\n",
    "                                         (\"human\",\"Tell me about {concept}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e492d-7f79-4065-94f9-9c2574841744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChatOpenAI model with default settings\n",
    "# This will use GPT-3.5-turbo by default\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722bbc6-6ad4-45a5-aa13-17877e774586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain using the pipe operator (|) - modern LangChain syntax\n",
    "# This connects the prompt template to the LLM in sequence\n",
    "# The output of prompt becomes the input to llm\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70e49d3-7616-45b5-adee-e382b593b879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subject\": \"physics\",\n",
      "  \"concept\": \"galaxy\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"subject\": \"physics\",\n",
      "  \"concept\": \"galaxy\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a physics teacher\\nHuman: Tell me about galaxy\"\n",
      "  ]\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [148ms] LLM run errored with error:\n",
      "\u001b[0m\"AuthenticationError(\\\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: <YOUR_AP**KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\\\")Traceback (most recent call last):\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 776, in generate\\n    self._generate_with_cache(\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 1022, in _generate_with_cache\\n    result = self._generate(\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\\\", line 995, in _generate\\n    response = self.client.create(**payload)\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/openai/_utils/_utils.py\\\", line 287, in wrapper\\n    return func(*args, **kwargs)\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\\\", line 925, in create\\n    return self._post(\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/openai/_base_client.py\\\", line 1242, in post\\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/openai/_base_client.py\\\", line 1037, in request\\n    raise self._make_status_error_from_response(err.response) from None\\n\\n\\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <YOUR_AP**KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RunnableSequence] [154ms] Chain run errored with error:\n",
      "\u001b[0m\"AuthenticationError(\\\"Error code: 401 - {'error': {'message': 'Incorrect API key provided: <YOUR_AP**KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\\\")Traceback (most recent call last):\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 3047, in invoke\\n    input_ = context.run(step.invoke, input_, config)\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 372, in invoke\\n    self.generate_prompt(\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 957, in generate_prompt\\n    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 776, in generate\\n    self._generate_with_cache(\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 1022, in _generate_with_cache\\n    result = self._generate(\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\\\", line 995, in _generate\\n    response = self.client.create(**payload)\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/openai/_utils/_utils.py\\\", line 287, in wrapper\\n    return func(*args, **kwargs)\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py\\\", line 925, in create\\n    return self._post(\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/openai/_base_client.py\\\", line 1242, in post\\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\\n\\n\\n  File \\\"/opt/conda/envs/genai-conda-env/lib/python3.10/site-packages/openai/_base_client.py\\\", line 1037, in request\\n    raise self._make_status_error_from_response(err.response) from None\\n\\n\\nopenai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <YOUR_AP**KEY>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain with variables - debugging output will show execution details\n",
    "# Since set_debug(True) is enabled, you'll see detailed trace information\n",
    "chain.invoke({\"subject\":\"physics\",\"concept\":\"galaxy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea148a9-ffc6-40f7-adad-750805980631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688458e-f936-4f88-86c8-9e12481de403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
