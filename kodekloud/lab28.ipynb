{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88f587a",
   "metadata": {},
   "source": [
    "# Lab 28: Document Processing Chains - Basic Chain Architecture\n",
    "\n",
    "## Learning Objectives\n",
    "In this lab, you will learn how to:\n",
    "- Build document processing chains using LangChain's high-level chain abstractions\n",
    "- Load and process multiple web documents simultaneously for content analysis\n",
    "- Create document-focused chains without retrieval or vector storage\n",
    "- Use `create_stuff_documents_chain` for direct document processing\n",
    "- Understand the difference between simple document chains and full RAG systems\n",
    "- Process multiple data sources for comparative analysis and summarization\n",
    "\n",
    "## Overview\n",
    "This lab introduces LangChain's chain abstractions for document processing, focusing on direct document manipulation without the complexity of vector stores or retrieval systems. You'll learn how to build chains that can process multiple documents at once, making it ideal for content analysis, summarization, and comparison tasks. This represents a simpler alternative to full RAG systems when you need to process a known set of documents rather than search through large knowledge bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ea211-6277-46e3-aaca-3b4c3520c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Processing Chain Implementation - Essential Imports\n",
    "# This lab demonstrates basic document processing using LangChain's high-level chain abstractions\n",
    "# Focus on direct document processing without vector storage or retrieval complexity\n",
    "\n",
    "# Language Model and Prompt Components\n",
    "from langchain_openai import ChatOpenAI  # OpenAI's chat model for content analysis\n",
    "from langchain_core.prompts import ChatPromptTemplate  # Chat-style prompt templates\n",
    "\n",
    "# Document Loading\n",
    "from langchain_community.document_loaders import WebBaseLoader  # Multi-URL web content loading\n",
    "\n",
    "# High-Level Chain Abstractions\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain  # Document processing chain factory\n",
    "\n",
    "print(\"üì¶ Document processing chain components imported\")\n",
    "print(\"üîß Focus: Direct document processing without vector storage\")\n",
    "print(\"üìÑ Capability: Multi-document loading and analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Configuration\n",
    "# Configure authentication for OpenAI's chat model\n",
    "import os\n",
    "\n",
    "# Set OpenAI API key for language model access\n",
    "# Required for ChatOpenAI model used in document processing\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af5b7bd-d5cf-4ed4-a87e-3c2549963dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target URLs for Multi-Document Analysis\n",
    "# Define multiple TechCrunch articles about AI companies and their latest models\n",
    "# This demonstrates processing multiple related documents for comparative analysis\n",
    "\n",
    "# URL 1: Microsoft's investment in Mistral AI - covers partnership and business aspects\n",
    "URL1 = \"https://techcrunch.com/2024/02/27/microsoft-made-a-16-million-investment-in-mistral-ai/\"\n",
    "\n",
    "# URL 2: AI21 Labs' new model announcement - covers technical specifications and efficiency\n",
    "URL2 = \"https://techcrunch.com/2024/03/28/ai21-labs-new-text-generating-ai-model-is-more-efficient-than-most/\"\n",
    "\n",
    "print(\"üåê Target documents configured:\")\n",
    "print(f\"üì∞ Article 1: Microsoft-Mistral AI partnership\")\n",
    "print(f\"üì∞ Article 2: AI21 Labs model announcement\")\n",
    "print(\"üîç Ready for multi-document comparative analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0bd239-0fe8-41b5-a7fa-671b919742f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Multiple Web Documents Simultaneously\n",
    "# WebBaseLoader can process multiple URLs in a single operation\n",
    "# This is efficient for analyzing related documents together\n",
    "\n",
    "# Multi-URL loading process:\n",
    "# 1. Fetches content from both TechCrunch articles\n",
    "# 2. Extracts clean text from HTML content\n",
    "# 3. Creates document objects with metadata for each URL\n",
    "# 4. Returns a list of documents ready for processing\n",
    "loader = WebBaseLoader([URL1, URL2])\n",
    "data = loader.load()\n",
    "\n",
    "print(f\"üìö Successfully loaded {len(data)} web documents\")\n",
    "print(\"üîç Documents contain AI company news and model announcements\")\n",
    "\n",
    "# Display document information\n",
    "for i, doc in enumerate(data, 1):\n",
    "    print(f\"üìÑ Document {i}: {len(doc.page_content)} characters\")\n",
    "    print(f\"üîó Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"üìã Preview: {doc.page_content[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7890f7-2e51-42d0-8f68-1d62d02d5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Chat-Style Prompt Template for Document Analysis\n",
    "# ChatPromptTemplate provides a conversational interface for document processing\n",
    "# Designed for analyzing multiple documents to extract specific information\n",
    "\n",
    "# Prompt design for model comparison task:\n",
    "# - System message format for clear instruction context\n",
    "# - Focuses on extracting model information from Mistral and AI21 Labs\n",
    "# - {context} placeholder will be filled with loaded document content\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"What models are launched by Mistral and AI21 Labs:\\n\\n{context}\")\n",
    "])\n",
    "\n",
    "print(\"üìù Chat prompt template created\")\n",
    "print(\"üéØ Task: Extract model information from company announcements\")\n",
    "print(\"üìä Focus: Mistral AI and AI21 Labs model launches\")\n",
    "print(\"üîß Template uses {context} placeholder for document content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b945105-2aee-4b4a-9275-c8267df04325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Language Model for Document Analysis\n",
    "# ChatOpenAI provides the analytical capability for document processing\n",
    "# Will analyze loaded web content to extract model information\n",
    "\n",
    "# GPT-3.5-turbo configuration:\n",
    "# - Cost-effective model for document analysis tasks\n",
    "# - Sufficient capability for extracting structured information\n",
    "# - Good balance of performance and efficiency for content analysis\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "print(\"ü§ñ ChatOpenAI language model initialized\")\n",
    "print(\"üí¨ Model: GPT-3.5-turbo for document analysis\")\n",
    "print(\"üìä Ready to process web content and extract model information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529830b3-2127-47ef-a9b5-09d356573255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Document Processing Chain\n",
    "# create_stuff_documents_chain builds a high-level chain for document analysis\n",
    "# \"Stuff\" approach concatenates all documents into a single prompt for processing\n",
    "\n",
    "# Document chain architecture:\n",
    "# 1. Takes a list of documents as input\n",
    "# 2. Combines document content into the prompt template's {context} placeholder\n",
    "# 3. Sends the filled prompt to the language model\n",
    "# 4. Returns the model's analysis of the document content\n",
    "\n",
    "# This approach is ideal for:\n",
    "# - Small to medium document sets that fit in model context\n",
    "# - Comparative analysis across multiple documents\n",
    "# - Extracting specific information from known document sets\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "print(\"‚õìÔ∏è Document processing chain created!\")\n",
    "print(\"üìÑ Type: Stuff documents chain (concatenates all documents)\")\n",
    "print(\"üîß Architecture: Documents ‚Üí Prompt ‚Üí LLM ‚Üí Analysis\")\n",
    "print(\"üéØ Optimized for multi-document comparative analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdae796-b70e-4702-9a11-0ac722882e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Document Processing Chain\n",
    "# Invoke the chain with loaded documents to extract model information\n",
    "# The chain will analyze both TechCrunch articles simultaneously\n",
    "\n",
    "print(\"üöÄ Executing document processing chain...\")\n",
    "print(\"üìä Analyzing articles about Mistral AI and AI21 Labs\")\n",
    "print(\"üîç Extracting information about launched models\")\n",
    "print()\n",
    "\n",
    "# Chain execution process:\n",
    "# 1. Takes the loaded documents as context\n",
    "# 2. Fills the prompt template with document content\n",
    "# 3. Sends combined prompt to GPT-3.5-turbo\n",
    "# 4. Returns analysis focusing on model launches\n",
    "result = chain.invoke({\"context\": data})\n",
    "\n",
    "print(\"üí¨ Document Analysis Result:\")\n",
    "print(\"=\" * 50)\n",
    "print(result)\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"‚úÖ Successfully analyzed multiple documents for model information\")\n",
    "print(\"üìä Chain processed both articles to extract relevant details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47365d",
   "metadata": {},
   "source": [
    "## Key Takeaways and Chain Architecture Insights\n",
    "\n",
    "### What You've Accomplished\n",
    "1. **Document Processing Chain**: Built a simple, efficient chain for analyzing multiple documents\n",
    "2. **Multi-Document Loading**: Processed multiple web sources simultaneously for comparative analysis\n",
    "3. **High-Level Abstractions**: Used LangChain's chain factories for rapid development\n",
    "4. **Content Analysis**: Extracted specific information from unstructured web content\n",
    "5. **Simplified Architecture**: Demonstrated document processing without complex retrieval systems\n",
    "\n",
    "### Technical Architecture Comparison\n",
    "\n",
    "| Aspect | Lab 28 (Document Chain) | Labs 26-27 (RAG Systems) |\n",
    "|--------|-------------------------|---------------------------|\n",
    "| **Complexity** | Simple, direct processing | Complex retrieval pipeline |\n",
    "| **Components** | Loader + Chain | Loader + Splitter + Embeddings + Vector Store + Retriever + Chain |\n",
    "| **Use Case** | Known document sets | Large knowledge bases |\n",
    "| **Processing** | All documents at once | Retrieve relevant chunks |\n",
    "| **Performance** | Fast for small sets | Scalable for large collections |\n",
    "\n",
    "### When to Use Document Chains vs RAG\n",
    "**Document Chains (Lab 28) are ideal for:**\n",
    "- Analyzing a small, known set of documents\n",
    "- Comparative analysis across multiple sources\n",
    "- Content summarization and extraction tasks\n",
    "- Quick prototyping and simple document processing\n",
    "- When documents fit within model context limits\n",
    "\n",
    "**RAG Systems (Labs 26-27) are better for:**\n",
    "- Large document collections or knowledge bases\n",
    "- Question-answering with unknown information needs\n",
    "- When documents exceed model context limits\n",
    "- Production systems requiring semantic search\n",
    "- Scalable, long-term knowledge management\n",
    "\n",
    "### Production Considerations\n",
    "- **Context Limits**: Document chains are limited by model context size\n",
    "- **Cost Efficiency**: Lower token usage for small document sets\n",
    "- **Simplicity**: Easier to debug and maintain than full RAG systems\n",
    "- **Flexibility**: Quick to adapt for different document analysis tasks\n",
    "\n",
    "### Real-World Applications\n",
    "- **News Analysis**: Comparing coverage across multiple news sources\n",
    "- **Research Synthesis**: Analyzing academic papers on specific topics\n",
    "- **Market Intelligence**: Processing competitor announcements and reports\n",
    "- **Content Curation**: Extracting key information from industry publications\n",
    "- **Compliance Review**: Analyzing policy documents and regulatory updates\n",
    "\n",
    "### Development Benefits\n",
    "- **Rapid Prototyping**: Quick setup for document analysis experiments\n",
    "- **Learning Path**: Stepping stone toward understanding more complex RAG systems\n",
    "- **Component Reuse**: Prompt templates and LLM configurations easily transferable\n",
    "- **Clear Separation**: Focus on chain logic without retrieval complexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
