{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88bae5a4",
   "metadata": {},
   "source": [
    "# Lab 27: Web-Based RAG System - Real-Time Information Retrieval\n",
    "\n",
    "## Learning Objectives\n",
    "In this lab, you will learn how to:\n",
    "- Build a complete RAG system that processes live web content for up-to-date information retrieval\n",
    "- Load and extract content from web pages using WebBaseLoader for HTML processing\n",
    "- Implement the same RAG pipeline architecture with web-based content sources\n",
    "- Understand how to adapt RAG systems for dynamic, frequently-updated content\n",
    "- Compare web-based RAG with document-based RAG for different use cases\n",
    "- Build systems that can answer questions about current events and online information\n",
    "\n",
    "## Overview\n",
    "This lab extends the RAG system architecture to work with web content, enabling real-time information retrieval from online sources. You'll learn how to process HTML content, handle web-specific challenges, and create question-answering systems that can work with the latest information from websites. This is essential for building AI systems that need access to current, frequently-updated information rather than static documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af44e79-f4fd-454e-b8c5-2b0d368be36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web-Based RAG System Implementation - Essential Imports\n",
    "# This lab demonstrates adapting the RAG architecture for real-time web content processing\n",
    "# enabling question-answering systems that work with live, frequently-updated information\n",
    "\n",
    "# Web Content Loading and Processing\n",
    "from langchain_community.document_loaders import WebBaseLoader  # HTML content extraction from web pages\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Intelligent text chunking for web content\n",
    "\n",
    "# Vector Storage and Embeddings (same as PDF RAG)\n",
    "from langchain_openai import OpenAIEmbeddings  # High-quality semantic embeddings for web text\n",
    "from langchain_chroma import Chroma  # Vector database for similarity search\n",
    "\n",
    "# LLM and Chain Components (consistent RAG architecture)\n",
    "from langchain_openai import ChatOpenAI  # OpenAI's chat model for answer generation\n",
    "from langchain.prompts import PromptTemplate  # Structured prompt templates\n",
    "from langchain_core.runnables import RunnablePassthrough  # Data flow management\n",
    "from langchain_core.output_parsers import StrOutputParser  # Clean string output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d932fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Configuration\n",
    "# Configure authentication for OpenAI services (embeddings and chat model)\n",
    "import os\n",
    "\n",
    "# Set OpenAI API key for embedding generation and LLM inference\n",
    "# Required for both text-embedding-3-large model and ChatOpenAI model\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bb8a9-6853-48b5-ba2f-e6d770cf83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Web Content Loader for Real-Time Information\n",
    "# WebBaseLoader extracts clean text content from HTML web pages\n",
    "# Essential for building RAG systems that work with current, online information\n",
    "\n",
    "# Target URL: The Verge article about Meta's AI assistant and Llama 3\n",
    "# This demonstrates processing current tech news and product announcements\n",
    "URL = \"https://www.theverge.com/2024/4/18/24133808/meta-ai-assistant-llama-3-chatgpt-openai-rival\"\n",
    "\n",
    "# WebBaseLoader capabilities:\n",
    "# - Fetches web page content via HTTP requests\n",
    "# - Parses HTML to extract readable text content\n",
    "# - Filters out navigation, ads, and boilerplate content\n",
    "# - Preserves article structure and formatting\n",
    "loader = WebBaseLoader(URL)\n",
    "\n",
    "print(\"üåê Web loader initialized for The Verge article\")\n",
    "print(\"üì∞ URL: Meta AI assistant and Llama 3 announcement\")\n",
    "print(\"üîß WebBaseLoader will extract clean text from HTML content\")\n",
    "print(\"üìä Content will be processed for real-time question answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d41e1-01ef-4025-ae4b-73d75e6b7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Extract Web Page Content\n",
    "# The load_and_split() method fetches the web page and extracts clean text content\n",
    "# Unlike PDF processing, web content typically results in a single document object\n",
    "\n",
    "# Web content loading process:\n",
    "# 1. HTTP request to fetch the web page\n",
    "# 2. HTML parsing to extract main content\n",
    "# 3. Text cleaning to remove HTML tags, navigation, ads\n",
    "# 4. Content structuring for further processing\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(f\"üåê Successfully loaded web content: {len(pages)} document(s)\")\n",
    "print(\"üì∞ Extracted clean text from HTML article\")\n",
    "print(\"üîç Content ready for chunking and embedding\")\n",
    "\n",
    "# Display information about the loaded web content\n",
    "if pages:\n",
    "    print(f\"üìÑ Content preview: {pages[0].page_content[:300]}...\")\n",
    "    print(f\"üè∑Ô∏è Metadata: {pages[0].metadata}\")\n",
    "    print(f\"üìä Total content length: {len(pages[0].page_content)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5d57da-6a67-48b3-8bef-5da225ef2a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Text Chunking for Web Content Processing\n",
    "# Apply the same intelligent chunking strategy used for PDF documents\n",
    "# Consistent chunking parameters ensure optimal retrieval performance across content types\n",
    "\n",
    "# Configure text splitter with proven parameters:\n",
    "# - chunk_size=200: Small chunks for precise retrieval and focused context\n",
    "# - chunk_overlap=50: 25% overlap ensures context continuity between chunks\n",
    "# These parameters work well for both PDF and web content processing\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "\n",
    "# Split web content into optimized chunks for vector storage\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "print(f\"üì¶ Split web content into {len(chunks)} chunks\")\n",
    "print(f\"üìè Consistent chunking: 200 characters with 50-character overlap\")\n",
    "print(f\"üéØ Optimized for precise retrieval from web article content\")\n",
    "\n",
    "# Display chunk statistics for web content\n",
    "if chunks:\n",
    "    avg_length = sum(len(chunk.page_content) for chunk in chunks) / len(chunks)\n",
    "    print(f\"üìä Average chunk length: {avg_length:.1f} characters\")\n",
    "    print(f\"üîç Sample chunk: {chunks[0].page_content[:150]}...\")\n",
    "    print(f\"üì∞ Web content successfully prepared for vector storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7c9a6-ab93-4dec-8e8f-cf3cd68fca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize High-Quality Embedding Model for Web Content\n",
    "# Using the same OpenAI text-embedding-3-large model ensures consistent performance\n",
    "# across different content sources (PDF documents, web pages, etc.)\n",
    "\n",
    "# Configure the most advanced OpenAI embedding model:\n",
    "# - 3072 dimensions for rich semantic representation\n",
    "# - Excellent performance on diverse content types\n",
    "# - Optimized for both formal documents and web article content\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "print(\"üöÄ OpenAI Embeddings initialized with text-embedding-3-large\")\n",
    "print(\"üìê Generates 3072-dimensional vectors for semantic search\")\n",
    "print(\"üåê Optimized for diverse content: web articles, news, technical content\")\n",
    "print(\"üéØ Consistent embedding quality across PDF and web content sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc9e92c-b0cb-439c-ae89-3549d38e35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vector Database from Web Content Chunks\n",
    "# Apply the same vector storage approach used for PDF documents\n",
    "# Demonstrates the flexibility of RAG architecture across different content sources\n",
    "\n",
    "# The from_documents() method performs the complete embedding pipeline:\n",
    "# 1. Generates embeddings for each web content chunk\n",
    "# 2. Creates Chroma vector database instance\n",
    "# 3. Stores embedded chunks with original text and web metadata\n",
    "# 4. Builds similarity search indexes for fast question-answering\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
    "\n",
    "print(\"üóÑÔ∏è Vector store created from web content!\")\n",
    "print(f\"üìö Embedded and stored {len(chunks)} web article chunks\")\n",
    "print(\"üåê Vector database contains real-time information from The Verge\")\n",
    "print(\"‚ö° Ready for semantic search on current tech news and AI developments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22423c5-db12-418d-8f5c-548a4326930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Web Content Retriever\n",
    "# Convert vector store into a retriever for seamless integration with RAG chain\n",
    "# Same interface as PDF RAG system, demonstrating architectural consistency\n",
    "\n",
    "# as_retriever() creates a standardized interface that:\n",
    "# - Accepts questions about web content and converts them to embeddings\n",
    "# - Performs similarity search against stored web article vectors\n",
    "# - Returns most relevant chunks about current AI developments\n",
    "# - Integrates seamlessly with the question-answering pipeline\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"üîç Web content retriever initialized\")\n",
    "print(\"üìä Retriever will find relevant chunks from The Verge article\")\n",
    "print(\"üéØ Semantic search on current Meta AI and Llama 3 information\")\n",
    "print(\"‚ö° Ready for real-time question answering about tech developments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781d7dc-78ff-40f8-ad23-dfd2994f29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Formatting Utility Function\n",
    "# Identical to PDF RAG system - demonstrates reusable components across content types\n",
    "# Prepares web content chunks for optimal LLM processing\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"\n",
    "    Format retrieved web content chunks for LLM consumption.\n",
    "    \n",
    "    Args:\n",
    "        docs: List of retrieved document chunks from web content vector search\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted string with content separated by double newlines\n",
    "    \"\"\"\n",
    "    # Join web content chunks with clear separators for better LLM comprehension\n",
    "    # Double newlines create clear boundaries between different article sections\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "print(\"üìù Document formatter function defined\")\n",
    "print(\"üåê Converts retrieved web content into clean context for LLM\")\n",
    "print(\"üîß Same formatting approach works for both PDF and web content\")\n",
    "print(\"üìã Maintains clear separation between different content chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dabd4cf-3cab-478b-9c58-6093a282add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Language Model for Web Content Question Answering\n",
    "# Same ChatOpenAI configuration as PDF RAG system\n",
    "# Demonstrates how LLM components work consistently across different content sources\n",
    "\n",
    "# ChatOpenAI configuration for web-based RAG:\n",
    "# - Uses GPT-3.5-turbo by default (cost-effective and fast)\n",
    "# - Processes web content context to generate accurate answers\n",
    "# - Maintains factual accuracy by staying within retrieved information\n",
    "# - Handles current events and technical information effectively\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "print(\"ü§ñ ChatOpenAI language model initialized\")\n",
    "print(\"üí¨ Using GPT-3.5-turbo for web content question answering\")\n",
    "print(\"üì∞ Model will generate answers based on current tech article content\")\n",
    "print(\"‚úÖ Ready to process questions about Meta AI, Llama 3, and current developments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930dd66a-6371-430b-abc6-55c64144578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Structured Prompt Template for Web-Based RAG\n",
    "# Identical prompt template structure as PDF RAG system\n",
    "# Demonstrates consistency and reusability of RAG architecture components\n",
    "\n",
    "# The same prompt design principles apply to web content:\n",
    "# 1. Define clear role as factual question-answer bot\n",
    "# 2. Emphasize responding only from provided web article context\n",
    "# 3. Include fallback behavior for information not in the article\n",
    "# 4. Use clear variable placeholders for dynamic web content\n",
    "template = \"\"\"SYSTEM: You are a question answer bot. \n",
    "                 Be factual in your response.\n",
    "                 Respond to the following question: {question} only from \n",
    "                 the below context :{context}. \n",
    "                 If you don't know the answer, just say that you don't know.\n",
    "               \"\"\"\n",
    "\n",
    "# Convert template string into a LangChain PromptTemplate object\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "print(\"üìù Web RAG prompt template created\")\n",
    "print(\"üéØ Template ensures factual responses based on web article content\")\n",
    "print(\"üö´ Prevents hallucination - answers only from retrieved web content\")\n",
    "print(\"üîß Variables: {question} for user query, {context} for web article chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf6e93-b3f6-4aae-88ad-6dd446ef9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Complete Web-Based RAG Question-Answering Chain\n",
    "# Identical architecture to PDF RAG system - demonstrates RAG pattern consistency\n",
    "# Shows how the same pipeline works for different content sources\n",
    "\n",
    "# Web RAG Chain Architecture (same as PDF RAG):\n",
    "# 1. Input: User question about web content\n",
    "# 2. Parallel Processing:\n",
    "#    - retriever | format_docs: Finds relevant web article chunks and formats context\n",
    "#    - RunnablePassthrough(): Passes the original question unchanged\n",
    "# 3. prompt: Combines web content context and question into structured prompt\n",
    "# 4. llm: Generates answer based on web article information\n",
    "# 5. StrOutputParser(): Extracts clean string response\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚õìÔ∏è Complete web-based RAG chain constructed!\")\n",
    "print(\"üîÑ Pipeline: Question ‚Üí Retrieve Web Content ‚Üí Format ‚Üí Generate ‚Üí Parse\")\n",
    "print(\"üåê Parallel processing: Web content retrieval + Question passthrough\")\n",
    "print(\"üéØ End-to-end system ready for real-time web content question answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b284fe9-053b-40f5-829e-1789e47c7574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Web RAG System with Current Tech Question\n",
    "# Test the system with a question about recent AI developments\n",
    "# Demonstrates real-time information retrieval from web sources\n",
    "\n",
    "print(\"‚ùì Testing web RAG system with current AI technology question...\")\n",
    "print(\"üîç Question: 'What's the size of the largest Llama 3 model?'\")\n",
    "print(\"üåê System will search through The Verge article for Llama 3 information\")\n",
    "print()\n",
    "\n",
    "# Invoke the complete web RAG chain:\n",
    "# 1. Retrieves relevant chunks about Llama 3 model specifications\n",
    "# 2. Formats web content context for the language model\n",
    "# 3. Generates accurate answer based on current article information\n",
    "# 4. Returns factual response about latest AI developments\n",
    "response = chain.invoke(\"What's the size of the largest Llama 3 model?\")\n",
    "\n",
    "print(\"üí¨ Web RAG System Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(response)\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"‚úÖ Web RAG system successfully answered question using current web content\")\n",
    "print(\"üåê Response is grounded in real-time information from The Verge article\")\n",
    "print(\"üì∞ Demonstrates RAG system capability with frequently-updated online sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2f5abd",
   "metadata": {},
   "source": [
    "## Key Takeaways and Web RAG Insights\n",
    "\n",
    "### What You've Accomplished\n",
    "1. **Web-Based RAG System**: Adapted the RAG architecture for real-time web content processing\n",
    "2. **Content Diversity**: Demonstrated RAG flexibility across different source types (PDF vs Web)\n",
    "3. **Current Information**: Built system capable of processing frequently-updated online content\n",
    "4. **Architectural Consistency**: Reused same components and patterns from PDF RAG system\n",
    "5. **Real-Time Retrieval**: Created question-answering system for current events and developments\n",
    "\n",
    "### Technical Comparison: PDF vs Web RAG\n",
    "| Component | PDF RAG (Lab 26) | Web RAG (Lab 27) |\n",
    "|-----------|------------------|------------------|\n",
    "| **Loader** | PyPDFLoader | WebBaseLoader |\n",
    "| **Content Type** | Static documents | Dynamic web pages |\n",
    "| **Update Frequency** | Infrequent | Real-time |\n",
    "| **Processing** | Page-based chunks | Article-based chunks |\n",
    "| **Use Cases** | Policies, manuals | News, current events |\n",
    "\n",
    "### Architectural Advantages\n",
    "- **Component Reusability**: Same text splitter, embeddings, vector store, and chain architecture\n",
    "- **Consistent Performance**: Identical chunking and retrieval strategies across content types\n",
    "- **Scalable Design**: Easy to extend to additional content sources (APIs, databases, etc.)\n",
    "- **Unified Interface**: Same question-answering experience regardless of content source\n",
    "\n",
    "### Web RAG Specific Benefits\n",
    "- **Current Information**: Access to latest news, announcements, and developments\n",
    "- **Dynamic Content**: Handles frequently-updated online sources\n",
    "- **Rich Metadata**: Web pages provide URL, publication date, and source information\n",
    "- **Broad Coverage**: Can process diverse web content from news sites, blogs, documentation\n",
    "\n",
    "### Production Considerations for Web RAG\n",
    "- **Content Freshness**: Implement regular re-indexing for frequently-updated sources\n",
    "- **Rate Limiting**: Respect website rate limits and robots.txt policies\n",
    "- **Content Quality**: Filter and validate web content for accuracy and relevance\n",
    "- **Legal Compliance**: Ensure proper permissions for web content usage\n",
    "\n",
    "### Real-World Applications\n",
    "- **News Analysis**: Question-answering systems for current events and breaking news\n",
    "- **Market Research**: Real-time analysis of industry developments and trends\n",
    "- **Product Updates**: Customer support systems with latest product information\n",
    "- **Compliance Monitoring**: Track regulatory changes and policy updates\n",
    "- **Competitive Intelligence**: Monitor competitor announcements and developments\n",
    "\n",
    "### Integration Possibilities\n",
    "- **Hybrid Systems**: Combine PDF and web RAG for comprehensive knowledge bases\n",
    "- **Multi-Source Retrieval**: Aggregate information from documents and web sources\n",
    "- **Automated Updates**: Schedule regular web content indexing for fresh information\n",
    "- **Source Attribution**: Track and cite specific web sources in generated responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
