{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "652ea9d8",
   "metadata": {},
   "source": [
    "# Lab 18: Configurable Fields in LangChain\n",
    "\n",
    "This lab demonstrates how to create configurable chains using ConfigurableField for dynamic runtime configuration. You'll learn:\n",
    "- How to make chain components configurable at runtime\n",
    "- Using `ConfigurableField` to allow model switching\n",
    "- Dynamic configuration without recreating chains\n",
    "- Runtime parameter modification for flexible chain behavior\n",
    "- Comparing outputs from different model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d26ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import LangChain components for configurable field demonstration\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "# ConfigurableField enables runtime configuration of chain components\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "import os\n",
    "\n",
    "# Set up OpenAI API credentials\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c249c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a configurable ChatOpenAI model with runtime model selection\n",
    "# Default model is gpt-3.5-turbo, but can be changed at runtime\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\").configurable_fields(\n",
    "    model_name=ConfigurableField(\n",
    "        id=\"model_name\",  # Unique identifier for this configuration\n",
    "        name=\"model name\",  # Human-readable name\n",
    "        description=\"The GPT model to use for chat\",  # Description for users\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a37e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a simple prompt template for haiku generation\n",
    "# The template accepts a subject variable for topic specification\n",
    "prompt = PromptTemplate.from_template(\"Write a Haiku on {subject}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a46ab4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create the configurable chain by combining prompt and model\n",
    "# The model's configurable fields are inherited by the chain\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a613ff48",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Invoke the chain with default configuration (gpt-3.5-turbo)\n",
    "# This uses the model specified during initialization\n",
    "chain.invoke({\"subject\": \"cat\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be0d94",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Invoke the chain with runtime configuration override\n",
    "# Uses with_config() to temporarily change the model to GPT-4\n",
    "# Compare the output quality difference between gpt-3.5-turbo and gpt-4\n",
    "# The chain structure remains the same, only the model parameter changes\n",
    "chain.with_config(configurable={\"model_name\": \"gpt-4\"}).invoke({\"subject\": \"cat\"})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
