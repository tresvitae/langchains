{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9db5a2a",
   "metadata": {},
   "source": [
    "# Lab 15: Custom Functions in LangChain with RunnableLambda\n",
    "\n",
    "This lab demonstrates how to integrate custom functions into LangChain chains using RunnableLambda. You'll learn:\n",
    "- How to create custom processing functions\n",
    "- Using `RunnableLambda` to wrap Python functions for chain integration\n",
    "- Combining LLM responses with custom logic\n",
    "- Visualizing chain structure with graph representation\n",
    "- Building complex processing pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b0242-54d3-465d-a11f-5f5949503ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LangChain components for custom function integration\n",
    "# RunnableLambda allows wrapping Python functions for use in chains\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API key for language model access\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defe4b7-a014-4f8b-bec7-e8e8b1b3787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom utility functions for text processing\n",
    "# These functions will be integrated into the LangChain pipeline\n",
    "\n",
    "def get_len(text):\n",
    "    \"\"\"Calculate and return the length of input text\"\"\"\n",
    "    print(f\"Text received: {text}\")  # Debug output to see the flow\n",
    "    return len(text)\n",
    "\n",
    "def to_titlecase(text):\n",
    "    \"\"\"Convert text to title case formatting\"\"\"\n",
    "    return text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273d8ebc-a5f2-4337-9cca-7b58c62c069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template for generating topic descriptions\n",
    "# The LLM output will be processed by our custom functions\n",
    "prompt = ChatPromptTemplate.from_template(\"Give me a one-line description of {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c0529-b0b2-433a-8319-6789ccd205d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChatOpenAI model for generating descriptions\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f3728-3558-46db-8cf5-eb1bbc577a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the model output to string format for custom function processing\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d51378a-226b-40ec-9ecc-e2f34d6928fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a complex chain with integrated custom functions\n",
    "# Flow: prompt → model → parse → titlecase → length calculation\n",
    "# RunnableLambda wraps our Python functions to make them chain-compatible\n",
    "chain = prompt | model | output_parser | RunnableLambda(to_titlecase) | RunnableLambda(get_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3401d02-59cc-4fd1-a65f-073512514bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the chain with custom function processing\n",
    "# Returns the final output (length) after applying all transformations\n",
    "chain.invoke({\"topic\":\"AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c574354-5269-4fd4-bfd3-700408895337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the chain structure in ASCII format\n",
    "# This shows the flow of data through each component including custom functions\n",
    "chain.get_graph().print_ascii()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
